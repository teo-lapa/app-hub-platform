#!/bin/bash
###############################################################################
# INSTALLAZIONE COMPLETA OLLAMA + LLAMA 3.2 3B SU JETSON
# Esegui questo script SUL JETSON per installare tutto automaticamente
###############################################################################

set -e

echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
echo "ğŸš€ INSTALLAZIONE OLLAMA + LLAMA 3.2 3B SU JETSON ORIN NANO"
echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
echo ""

# 1. VERIFICA SISTEMA
echo "ğŸ“Š Step 1/7: Verifica sistema..."
TOTAL_RAM=$(free -g | awk '/^Mem:/{print $2}')
echo "   RAM totale: ${TOTAL_RAM}GB"

if [ "$TOTAL_RAM" -lt 7 ]; then
    echo "   âš ï¸  Warning: RAM < 8GB, ma procedo comunque"
fi

# 2. INSTALLA OLLAMA
echo ""
echo "ğŸ“¥ Step 2/7: Installazione Ollama..."
if command -v ollama &> /dev/null; then
    echo "   âœ… Ollama giÃ  installato: $(ollama --version)"
else
    curl -fsSL https://ollama.com/install.sh | sh
    echo "   âœ… Ollama installato"
fi

# 3. AVVIA SERVIZIO
echo ""
echo "ğŸ”§ Step 3/7: Configurazione servizio..."
sudo systemctl enable ollama 2>/dev/null || true
sudo systemctl start ollama
sleep 3

if systemctl is-active --quiet ollama; then
    echo "   âœ… Servizio Ollama attivo"
else
    echo "   âš ï¸  Servizio non attivo, provo a startare manualmente..."
    ollama serve &
    sleep 5
fi

# 4. SCARICA MODELLO
echo ""
echo "ğŸ“¦ Step 4/7: Download Llama 3.2 3B (~2GB)..."
echo "   Questo richiede 2-5 minuti..."
if ollama list 2>/dev/null | grep -q "llama3.2:3b"; then
    echo "   âœ… Modello giÃ  presente"
else
    ollama pull llama3.2:3b
    echo "   âœ… Modello scaricato"
fi

# 5. TEST MODELLO
echo ""
echo "ğŸ§ª Step 5/7: Test modello..."
TEST_OUTPUT=$(ollama run llama3.2:3b "Rispondi solo con: OK" 2>&1 | tail -1)
echo "   Risposta test: $TEST_OUTPUT"
echo "   âœ… Modello funzionante"

# 6. CONFIGURA .ENV
echo ""
echo "âš™ï¸  Step 6/7: Configurazione environment..."
cd ~/jetson-deployment

if [ ! -f .env ]; then
    cp .env.example .env
    echo "   âœ… File .env creato"
fi

# Aggiorna .env con Ollama
if grep -q "USE_OLLAMA" .env; then
    sed -i 's/USE_OLLAMA=.*/USE_OLLAMA=true/' .env
else
    echo "USE_OLLAMA=true" >> .env
fi

if grep -q "OLLAMA_URL" .env; then
    sed -i 's|OLLAMA_URL=.*|OLLAMA_URL=http://localhost:11434|' .env
else
    echo "OLLAMA_URL=http://localhost:11434" >> .env
fi

if grep -q "OLLAMA_MODEL" .env; then
    sed -i 's/OLLAMA_MODEL=.*/OLLAMA_MODEL=llama3.2:3b/' .env
else
    echo "OLLAMA_MODEL=llama3.2:3b" >> .env
fi

echo "   âœ… Environment configurato"

# 7. RIAVVIA DOCKER
echo ""
echo "ğŸ³ Step 7/7: Riavvio servizi Docker..."
if command -v docker-compose &> /dev/null || command -v docker &> /dev/null; then
    docker-compose down 2>/dev/null || true
    docker-compose up -d --build
    echo "   âœ… Docker riavviato"
else
    echo "   âš ï¸  Docker non trovato, salta questo step"
fi

# SUMMARY
echo ""
echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
echo "âœ… INSTALLAZIONE COMPLETATA CON SUCCESSO!"
echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
echo ""
echo "ğŸ“Š Riepilogo:"
echo "   - Ollama:     INSTALLATO âœ“"
echo "   - Llama 3.2:  SCARICATO âœ“"
echo "   - Modello:    llama3.2:3b (~2GB)"
echo "   - Endpoint:   http://localhost:11434"
echo "   - Docker:     RIAVVIATO âœ“"
echo ""
echo "ğŸ’¡ Prossimi passi:"
echo "   1. Verifica logs: docker-compose logs -f ocr-server"
echo "   2. Dovresti vedere: ğŸ¤– AI Classifier: Ollama (Local)"
echo "   3. Testa su Vercel: https://your-app.vercel.app/jetson-ocr"
echo ""
echo "ğŸ‰ Ora classifichi documenti GRATIS con AI locale!"
echo ""
